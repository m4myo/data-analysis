{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd850323",
   "metadata": {},
   "source": [
    "# 1. Loading Modules and API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdbbd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import geocoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e18c5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "consumer_key = os.environ['API_KEY']\n",
    "consumer_secret = os.environ['API_KEY_SECRET']\n",
    "access_token = os.environ['ACCESS_TOKEN']\n",
    "access_token_secret = os.environ['ACCESS_TOKEN_SECRET']\n",
    "bearer_token = os.environ['BEARER_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67d7d1",
   "metadata": {},
   "source": [
    "# 2. API Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcb68963",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuth1UserHandler(\n",
    "  consumer_key, \n",
    "  consumer_secret, \n",
    "  access_token, \n",
    "  access_token_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4a2a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81743368",
   "metadata": {},
   "source": [
    "# 3. Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed25a351",
   "metadata": {},
   "source": [
    "## 3.1 Function for Location-specific trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537f474",
   "metadata": {},
   "source": [
    "We will create a method that \n",
    "1. converts **Location** to **Long & Lat** using geocoder.osm()\n",
    "2. get a response for the closest location in the form of WOEID using closet_trends()\n",
    "3. get place-specific trends by providing WOEID to get_place_trends()\n",
    "4. then, returns top 50 trending topics for that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4de6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trends(api, loc):\n",
    "    # Object that has location's latitude and longitude.\n",
    "    g = geocoder.osm(loc)\n",
    "    \n",
    "    # we will retrieve the closest latitude and longitude and apply as parameters to API's closest_trends() method.\n",
    "    closest_loc = api.closest_trends(g.lat, g.lng)\n",
    "    \n",
    "    # Once we get the closest_lo\n",
    "    trends = api.get_place_trends(closest_loc[0][\"woeid\"])\n",
    "    return trends[0][\"trends\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152085aa",
   "metadata": {},
   "source": [
    "## 3.2 Functions to Find Locations with Currently Available Trends\n",
    "Optional section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ef1fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations():\n",
    "    countries = []\n",
    "    available_trends = api.available_trends()\n",
    "    country_data = pd.DataFrame.from_records(available_trends)\n",
    "    \n",
    "    #The response contains unnecessary info such as parentid, url and 'Town' from placeType column, to be removed or filtered.\n",
    "    country_data = country_data.drop(columns = ['parentid'])\n",
    "    #towns = country_data['placeType'] == {'code': 7, 'name': 'Town'}\n",
    "    #country_data = country_data[~towns]\n",
    "    return country_data\n",
    "\n",
    "#country_location_data = get_locations()\n",
    "#country_location_data['country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c3dff",
   "metadata": {},
   "source": [
    "## 3.3 Function to find location-specific trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cd6ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_specific_trends(locations):\n",
    "    trends_in_countries = []\n",
    "    for location in locations:\n",
    "        trend = get_trends(api, location)\n",
    "        trend_data = pd.DataFrame.from_records(trend)\n",
    "        trend_data['country'] = location\n",
    "\n",
    "        # remove the rows if the tweet volume is not available\n",
    "        trend_data = trend_data[~trend_data['tweet_volume'].isna()]\n",
    "\n",
    "        # remove the promoted_content column as it serves no purpose\n",
    "        trend_data = trend_data.drop(columns = ['promoted_content'])\n",
    "\n",
    "        #remove any duplicates in the 'name' column since the location contents are more than one.\n",
    "        trend_data = trend_data.drop_duplicates(subset=['name'], keep='first')\n",
    "\n",
    "        # sort records by tweet_volume\n",
    "        trend_data = trend_data.sort_values('tweet_volume', ascending = False)\n",
    "        \n",
    "        trend_data = trend_data[['country','name','tweet_volume','url']]\n",
    "        trend_data.columns = ['country','trending_topic','tweet_volume','url']\n",
    "        trends_in_countries.append(trend_data)\n",
    "    return trends_in_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84047f8d",
   "metadata": {},
   "source": [
    "## 3.4 Functions to extract all hashtags and phrases trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "729fcbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(trend_list):\n",
    "    hashtags = []\n",
    "    for name in trend_list['trending_topic']:\n",
    "        if name not in hashtags:\n",
    "            if '#' in name:\n",
    "                hashtags.append(name)\n",
    "    return hashtags\n",
    "\n",
    "def extract_phrases(trend_list):\n",
    "    phrases = []\n",
    "    for name in trend_list['trending_topic']:\n",
    "        if name not in phrases:\n",
    "            if '#' not in name:\n",
    "                phrases.append(name)\n",
    "    return phrases\n",
    "#popular_hashtags = extract_hashtags(merged_df)\n",
    "#popular_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27966445",
   "metadata": {},
   "source": [
    "## 3.5 Function to export all records to CSV format\n",
    "(Optional cell below, uncomment the line and run the function to export the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20d6a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export2csv(trends_df):\n",
    "    trends_df.to_csv('export.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4771156",
   "metadata": {},
   "source": [
    "## 3.6 Function to find Top Tweets in a trend\n",
    "Find Top 50 tweets that are contributing to a trend. (50 is default number of tweets allowed by API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb4f8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendsetters(keywords, limit, until_date):\n",
    "    tweet_list = []\n",
    "    for keyword in keywords:\n",
    "        tweets = tweepy.Cursor(api.search_tweets,\n",
    "                               q=keyword + \"-is:retweet\",\n",
    "                               lang='en',\n",
    "                               tweet_mode='extended',\n",
    "                               result_type='popular',\n",
    "                               until=until_date).items(limit)\n",
    "        for tweet in tweets:\n",
    "            tweet_data = [keyword,\n",
    "                          tweet.user.screen_name,\n",
    "                          tweet.created_at,\n",
    "                          tweet.full_text, \n",
    "                          tweet.favorite_count, \n",
    "                          tweet.retweet_count\n",
    "                         ]\n",
    "            tweet_list.append(tweet_data)\n",
    "    trending_tweets_df = pd.DataFrame(tweet_list, columns = ['topic',\n",
    "                                                             'user',\n",
    "                                                             'created_at',\n",
    "                                                             'content',\n",
    "                                                             'favorites',\n",
    "                                                             'retweets'])\n",
    "    #Show only date, not time.\n",
    "    trending_tweets_df[\"created_at\"] = pd.to_datetime(trending_tweets_df[\"created_at\"]).dt.date\n",
    "    trending_tweets_df = trending_tweets_df.sort_values('favorites', ascending = False)    \n",
    "    return trending_tweets_df\n",
    "\n",
    "# trendsetters(query, limit, until_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ced1c",
   "metadata": {},
   "source": [
    "## 3.7 Function to retrieve tweets from a user\n",
    "Get as many tweets from a user's timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e482964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use while True to keep extracting 200 records at a time\n",
    "After one extraction, use the ID earliest created record,\n",
    "and start the extraction from the previous one for another 200 records.\n",
    "\"\"\"\n",
    "\n",
    "#Start recording from the latest tweet\n",
    "def loop_tweet_extraction(username):\n",
    "    tweets = api.user_timeline(screen_name=username, \n",
    "                               # 200 is the maximum allowed count\n",
    "                               count=3000,\n",
    "                               include_rts = False,\n",
    "                               tweet_mode = 'extended',\n",
    "                               exclude_replies = True\n",
    "                               )\n",
    "    all_tweets = []\n",
    "    all_tweets.extend(tweets)\n",
    "    oldest_id = tweets[-1].id\n",
    "    while True:\n",
    "        tweets = api.user_timeline(screen_name=username, \n",
    "                               # 200 is the maximum allowed count\n",
    "                               count=200,\n",
    "                               include_rts = False,\n",
    "                               max_id = oldest_id - 1,\n",
    "                               # Necessary to keep full_text \n",
    "                               # otherwise only the first 140 words are extracted\n",
    "                               tweet_mode = 'extended'\n",
    "                               )\n",
    "        if len(tweets) == 0:\n",
    "            break\n",
    "        oldest_id = tweets[-1].id\n",
    "        all_tweets.extend(tweets)\n",
    "        print('N of tweets downloaded till now {}'.format(len(all_tweets)))\n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d637e378",
   "metadata": {},
   "source": [
    "# 4. ANALYSIS CELLS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd63f7",
   "metadata": {},
   "source": [
    "###### A. Get trending topics by selected regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4869dba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>trending_topic</th>\n",
       "      <th>tweet_volume</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>United States</td>\n",
       "      <td>Soludo</td>\n",
       "      <td>192708.0</td>\n",
       "      <td>http://twitter.com/search?q=Soludo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>United States</td>\n",
       "      <td>#WWERaw</td>\n",
       "      <td>54950.0</td>\n",
       "      <td>http://twitter.com/search?q=%23WWERaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>United States</td>\n",
       "      <td>Mike Pence</td>\n",
       "      <td>103185.0</td>\n",
       "      <td>http://twitter.com/search?q=%22Mike+Pence%22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>United States</td>\n",
       "      <td>#WASvsPHI</td>\n",
       "      <td>26723.0</td>\n",
       "      <td>http://twitter.com/search?q=%23WASvsPHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>United States</td>\n",
       "      <td>Liz Cheney</td>\n",
       "      <td>91463.0</td>\n",
       "      <td>http://twitter.com/search?q=%22Liz+Cheney%22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country trending_topic  tweet_volume  \\\n",
       "29  United States         Soludo      192708.0   \n",
       "11  United States        #WWERaw       54950.0   \n",
       "35  United States     Mike Pence      103185.0   \n",
       "9   United States      #WASvsPHI       26723.0   \n",
       "12  United States     Liz Cheney       91463.0   \n",
       "\n",
       "                                             url  \n",
       "29            http://twitter.com/search?q=Soludo  \n",
       "11         http://twitter.com/search?q=%23WWERaw  \n",
       "35  http://twitter.com/search?q=%22Mike+Pence%22  \n",
       "9        http://twitter.com/search?q=%23WASvsPHI  \n",
       "12  http://twitter.com/search?q=%22Liz+Cheney%22  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldwide = ['Worldwide']\n",
    "asean = [\"Myanmar\", \"Thailand\",\"Singapore\", \"Malaysia\", \"Philippines\", \"Vietnam\", \"Indonesia\", \"Laos\", \"Cambodia\", \"Brunei\"]\n",
    "south_america = ['Brazil','Colombia','Argentina','Peru','Venezuela','Chile', 'Ecuador','Bolivia','Paraguay','Uruguay', 'Guyana','Suriname','French Guiana','Falkland Islands']\n",
    "\n",
    "# Select the location here inside the array\n",
    "select_country = ['United States']\n",
    "selected_locations = select_country\n",
    "\n",
    "# Select number of results to view. Max is 50.\n",
    "total_results = 5\n",
    "\n",
    "trends = get_location_specific_trends(selected_locations)\n",
    "# Merging dataframes from all locations selected\n",
    "trending_now = pd.concat(trends)\n",
    "trending_now.sample(total_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1060069",
   "metadata": {},
   "source": [
    "###### B. Get the hashtags available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eab7e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#WWERaw', '#WASvsPHI', '#HTTC']\n",
      "['Arizona', 'Kari Lake', 'Katie Hobbs', 'Eagles', 'Soludo', 'YOU LOST', 'Mike Pence', 'Liz Cheney', 'Pete Davidson', 'Ticketmaster', 'Graham', 'Terry', 'David Hundeyin', 'Slay', '8 Billion', 'McCain', 'Philly', 'Yale', 'Jalen', 'Layla', 'Heinicke', 'Klay', 'Hannity', 'Gannon']\n"
     ]
    }
   ],
   "source": [
    "hashtags = extract_hashtags(trending_now)\n",
    "phrases  = extract_phrases(trending_now)\n",
    "print(hashtags)\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e99d986",
   "metadata": {},
   "source": [
    "###### C. Pick a trending topic or list of topics and see the top tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "025637d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>rafaelshimunov</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>Did Twitter Blue tweet just cost Eli Lilly $LL...</td>\n",
       "      <td>419695</td>\n",
       "      <td>63634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>Previously, we issued a warning before suspens...</td>\n",
       "      <td>164469</td>\n",
       "      <td>12651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>litcapital</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>Twitter Blue erased a few billion in market ca...</td>\n",
       "      <td>119101</td>\n",
       "      <td>10633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>ZoeSchiffer</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>NEW: Twitter has suspended the launch of Twitt...</td>\n",
       "      <td>82453</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>MikeSington</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>The chaos continues. Twitter pulls the plug on...</td>\n",
       "      <td>77923</td>\n",
       "      <td>12203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>LilyPichu</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>I said Iâ€™d dye my hair blue if DRX won ðŸ˜Š itâ€™s ...</td>\n",
       "      <td>56949</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>MaryLTrump</td>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>Given historical precedent, conventional wisdo...</td>\n",
       "      <td>29339</td>\n",
       "      <td>5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>MuellerSheWrote</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>Getting to 51 is important because we wonâ€™t ha...</td>\n",
       "      <td>12533</td>\n",
       "      <td>3057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>InTheLittleWood</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>You not gonna see me apologizing for buying Tw...</td>\n",
       "      <td>8107</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter Blue</td>\n",
       "      <td>gawrgura</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>funny blue hedgehog does backflip (i made him ...</td>\n",
       "      <td>7528</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic             user  created_at  \\\n",
       "20  Twitter Blue   rafaelshimunov  2022-11-11   \n",
       "26  Twitter Blue         elonmusk  2022-11-06   \n",
       "22  Twitter Blue       litcapital  2022-11-11   \n",
       "23  Twitter Blue      ZoeSchiffer  2022-11-11   \n",
       "24  Twitter Blue      MikeSington  2022-11-11   \n",
       "9   Twitter Blue        LilyPichu  2022-11-13   \n",
       "27  Twitter Blue       MaryLTrump  2022-11-13   \n",
       "0   Twitter Blue  MuellerSheWrote  2022-11-14   \n",
       "42  Twitter Blue  InTheLittleWood  2022-11-06   \n",
       "4   Twitter Blue         gawrgura  2022-11-14   \n",
       "\n",
       "                                              content  favorites  retweets  \n",
       "20  Did Twitter Blue tweet just cost Eli Lilly $LL...     419695     63634  \n",
       "26  Previously, we issued a warning before suspens...     164469     12651  \n",
       "22  Twitter Blue erased a few billion in market ca...     119101     10633  \n",
       "23  NEW: Twitter has suspended the launch of Twitt...      82453      9998  \n",
       "24  The chaos continues. Twitter pulls the plug on...      77923     12203  \n",
       "9   I said Iâ€™d dye my hair blue if DRX won ðŸ˜Š itâ€™s ...      56949      1017  \n",
       "27  Given historical precedent, conventional wisdo...      29339      5893  \n",
       "0   Getting to 51 is important because we wonâ€™t ha...      12533      3057  \n",
       "42  You not gonna see me apologizing for buying Tw...       8107       120  \n",
       "4   funny blue hedgehog does backflip (i made him ...       7528       886  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick trending topic(s) by using hashtags (or) phrases variables or manually specifying it in an array\n",
    "query = ['Twitter Blue']\n",
    "\n",
    "# Incrase the limit to get more data\n",
    "limit = 100\n",
    "\n",
    "# Pick a date as latest available.\n",
    "until_date = \"2022-11-15\"\n",
    "\n",
    "# Select number of results to view. Max is 50. \n",
    "total_tweets_in_trend = 10\n",
    "\n",
    "trendsetter_tweets = trendsetters(query, limit, until_date)\n",
    "trendsetter_tweets = trendsetter_tweets.sort_values('favorites', ascending = False)\n",
    "\n",
    "trendsetter_tweets.head(total_tweets_in_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3662b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data if you want.\n",
    "#export2csv(trendsetter_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b8046",
   "metadata": {},
   "source": [
    "###### D. Pick a user to get retrieve tweets from their timeline as many as possible.\n",
    "(Disclaimer - Must not be used for any malicious intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc3bad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of tweets downloaded till now 203\n",
      "N of tweets downloaded till now 379\n",
      "N of tweets downloaded till now 546\n",
      "N of tweets downloaded till now 720\n",
      "N of tweets downloaded till now 892\n",
      "N of tweets downloaded till now 1072\n",
      "N of tweets downloaded till now 1256\n",
      "N of tweets downloaded till now 1429\n",
      "N of tweets downloaded till now 1603\n",
      "N of tweets downloaded till now 1779\n",
      "N of tweets downloaded till now 1962\n",
      "N of tweets downloaded till now 2141\n",
      "N of tweets downloaded till now 2337\n",
      "N of tweets downloaded till now 2526\n",
      "N of tweets downloaded till now 2717\n",
      "N of tweets downloaded till now 2780\n"
     ]
    }
   ],
   "source": [
    "username = 'david_perell'\n",
    "user_tweets = loop_tweet_extraction(username)\n",
    "\n",
    "outtweets = [[tweet.id_str, \n",
    "              tweet.user.id_str, \n",
    "              tweet.user.name, \n",
    "              tweet.created_at,\n",
    "              tweet.favorite_count,\n",
    "              tweet.retweet_count,\n",
    "              tweet.full_text.encode(\"utf-8\").decode(\"utf-8\")] \n",
    "             for idx,tweet in enumerate(user_tweets)]\n",
    "\n",
    "tweets_df = pd.DataFrame (outtweets, columns = [\"tweet_id\", \"user_id\",\"user_name\",\"created_at\", \"favorite_count\",\"retweet_count\",\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "728eb48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Perell</td>\n",
       "      <td>2022-11-14 04:08:17+00:00</td>\n",
       "      <td>The most common mistake that beginner writers ...</td>\n",
       "      <td>367</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Perell</td>\n",
       "      <td>2022-11-14 04:05:21+00:00</td>\n",
       "      <td>If I could send every student to one writing c...</td>\n",
       "      <td>3400</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Perell</td>\n",
       "      <td>2022-11-14 03:48:16+00:00</td>\n",
       "      <td>You have to think clearly in order to write cl...</td>\n",
       "      <td>235</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Perell</td>\n",
       "      <td>2022-11-14 03:37:44+00:00</td>\n",
       "      <td>Learning science has advanced a bunch over the...</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Perell</td>\n",
       "      <td>2022-11-14 03:18:47+00:00</td>\n",
       "      <td>People look at these surveys and say: â€œThe Lib...</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_name                created_at  \\\n",
       "0  David Perell 2022-11-14 04:08:17+00:00   \n",
       "1  David Perell 2022-11-14 04:05:21+00:00   \n",
       "2  David Perell 2022-11-14 03:48:16+00:00   \n",
       "3  David Perell 2022-11-14 03:37:44+00:00   \n",
       "4  David Perell 2022-11-14 03:18:47+00:00   \n",
       "\n",
       "                                               tweet  favorite_count  \\\n",
       "0  The most common mistake that beginner writers ...             367   \n",
       "1  If I could send every student to one writing c...            3400   \n",
       "2  You have to think clearly in order to write cl...             235   \n",
       "3  Learning science has advanced a bunch over the...             114   \n",
       "4  People look at these surveys and say: â€œThe Lib...             155   \n",
       "\n",
       "   retweet_count  \n",
       "0             21  \n",
       "1            465  \n",
       "2             25  \n",
       "3             12  \n",
       "4              7  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_final = tweets_df[['user_name','created_at','tweet','favorite_count','retweet_count']]\n",
    "tweets_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c507174c",
   "metadata": {},
   "source": [
    "# 5. To-be-continued - Brand Reputation Monitoring and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8d01c",
   "metadata": {},
   "source": [
    "### Brand Mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eaf968",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1422aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
